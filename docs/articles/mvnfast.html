<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>An Introduction to mvnfast • mvnfast</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">mvnfast</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../articles/mvnfast.html">Get Started</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/mfasiolo/mvnfast">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>An Introduction to mvnfast</h1>
                        <h4 class="author">Matteo Fasiolo</h4>
            
            <h4 class="date">2017-12-13</h4>
          </div>

    
    
<div class="contents">
<div id="introduction" class="section level2">
<h2 class="hasAnchor">
<a href="#introduction" class="anchor"></a>Introduction</h2>
<p>The <code>mvnfast</code> R package provides computationally efficient tools related to the multivariate normal and Student’s t distributions. The tools are generally faster than those provided by other packages, thanks to the use of C++ code through the <code>Rcpp</code>\<code>RcppArmadillo</code> packages and parallelization through the <code>OpenMP</code> API. The most important functions are:</p>
<ul>
<li>
<code><a href="../reference/rmvn.html">rmvn()</a></code>: simulates multivariate normal random vectors.</li>
<li>
<code><a href="../reference/rmvt.html">rmvt()</a></code>: simulates Student’s t normal random vectors.</li>
<li>
<code><a href="../reference/dmvn.html">dmvn()</a></code>: evaluates the probability density function of a multivariate normal distribution.<br>
</li>
<li>
<code><a href="../reference/dmvt.html">dmvt()</a></code>: evaluates the probability density function of a multivariate Student’s t distribution.<br>
</li>
<li>
<code><a href="../reference/maha.html">maha()</a></code>: evaluates mahalanobis distances.</li>
</ul>
<p>In the following sections we will benchmark each function against equivalent functions provided by other packages, while in the final section we provide an example application.</p>
</div>
<div id="simulating-multivariate-normal-or-students-t-random-vectors" class="section level2">
<h2 class="hasAnchor">
<a href="#simulating-multivariate-normal-or-students-t-random-vectors" class="anchor"></a>Simulating multivariate normal or Student’s t random vectors</h2>
<p>Simulating multivariate normal random variables is an essential step in many Monte Carlo algorithms (such as MCMC or Particle Filters), hence this operations has to be as fast as possible. Here we compare the <code>rmvn</code> function with the equivalent function <code>rmvnorm</code> (from the <code>mvtnorm</code> package) and <code>mvrnorm</code> (from the <code>MASS</code> package). In particular, we simulate <span class="math inline">\(10^4\)</span> twenty-dimensional random vectors:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">"microbenchmark"</span>)
<span class="kw">library</span>(<span class="st">"mvtnorm"</span>)
<span class="kw">library</span>(<span class="st">"mvnfast"</span>)
<span class="kw">library</span>(<span class="st">"MASS"</span>)
<span class="co"># We might also need to turn off BLAS parallelism </span>
<span class="kw">library</span>(<span class="st">"RhpcBLASctl"</span>)
<span class="kw"><a href="http://www.rdocumentation.org/packages/RhpcBLASctl/topics/RhpcBLASctl-package">blas_set_num_threads</a></span>(<span class="dv">1</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">N &lt;-<span class="st"> </span><span class="dv">10000</span>
d &lt;-<span class="st"> </span><span class="dv">20</span>

<span class="co"># Creating mean and covariance matrix</span>
mu &lt;-<span class="st"> </span><span class="dv">1</span>:d
tmp &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rnorm</span>(d^<span class="dv">2</span>), d, d)
mcov &lt;-<span class="st"> </span><span class="kw">tcrossprod</span>(tmp, tmp)

<span class="kw"><a href="http://www.rdocumentation.org/packages/microbenchmark/topics/microbenchmark">microbenchmark</a></span>(<span class="kw"><a href="../reference/rmvn.html">rmvn</a></span>(N, mu, mcov, <span class="dt">ncores =</span> <span class="dv">2</span>),
               <span class="kw"><a href="../reference/rmvn.html">rmvn</a></span>(N, mu, mcov),
               <span class="kw"><a href="http://www.rdocumentation.org/packages/mvtnorm/topics/Mvnorm">rmvnorm</a></span>(N, mu, mcov),
               <span class="kw"><a href="http://www.rdocumentation.org/packages/MASS/topics/mvrnorm">mvrnorm</a></span>(N, mu, mcov))</code></pre></div>
<pre><code>## Unit: milliseconds
##                           expr       min        lq      mean    median
##  rmvn(N, mu, mcov, ncores = 2)  3.002543  3.108198  4.673041  3.544022
##              rmvn(N, mu, mcov)  5.269046  5.461131  6.653810  5.602943
##           rmvnorm(N, mu, mcov) 15.196825 16.558912 23.353344 17.262071
##           mvrnorm(N, mu, mcov) 14.787562 16.195220 20.429942 16.605675
##         uq      max neval cld
##   4.233790 42.23806   100  a 
##   6.185731 46.17587   100  a 
##  18.707405 63.73079   100   b
##  17.317955 75.85460   100   b</code></pre>
<p>In this example <code>rmvn</code> cuts the computational time, relative to the alternatives, even when a single core is used. This gain is attributable to several factors: the use of C++ code and efficient numerical algorithms to simulate the random variables. Parallelizing the computation on two cores gives another appreciable speed-up. To be fair, it is necessary to point out that <code>rmvnorm</code> and <code>mvrnorm</code> have many more safety check on the user’s input than <code>rmvn</code>. This is true also for the functions described in the next sections.</p>
<p>Notice that this function does not use one of the Random Number Generators (RNGs) provided by R, but one of the parallel cryptographic RNGs described in (Salmon et al., 2011) and available <a href="http://www.sitmo.com">here</a>. It is important to point out that this RNG can safely be used in parallel, without risk of collisions between parallel sequence of random numbers, as detailed in the above reference.</p>
<p>We get similar performance gains when we simulate multivariate Student’s t random variables:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Here we have a conflict between namespaces</span>
<span class="kw"><a href="http://www.rdocumentation.org/packages/microbenchmark/topics/microbenchmark">microbenchmark</a></span>(mvnfast::<span class="kw"><a href="../reference/rmvt.html">rmvt</a></span>(N, mu, mcov, <span class="dt">df =</span> <span class="dv">3</span>, <span class="dt">ncores =</span> <span class="dv">2</span>),
               mvnfast::<span class="kw"><a href="../reference/rmvt.html">rmvt</a></span>(N, mu, mcov, <span class="dt">df =</span> <span class="dv">3</span>),
               mvtnorm::<span class="kw"><a href="../reference/rmvt.html">rmvt</a></span>(N, <span class="dt">delta =</span> mu, <span class="dt">sigma =</span> mcov, <span class="dt">df =</span> <span class="dv">3</span>))</code></pre></div>
<pre><code>## Unit: milliseconds
##                                                expr       min        lq
##      mvnfast::rmvt(N, mu, mcov, df = 3, ncores = 2)  5.669553  5.797279
##                  mvnfast::rmvt(N, mu, mcov, df = 3)  7.943431  8.062002
##  mvtnorm::rmvt(N, delta = mu, sigma = mcov, df = 3) 18.332169 20.087072
##      mean    median        uq       max neval cld
##   7.47863  5.930236  7.090085 107.66883   100  a 
##   8.89368  8.356582  9.400072  19.01358   100  a 
##  33.45673 21.200880 24.014178 134.50451   100   b</code></pre>
<p>When <code>d</code> and <code>N</code> are large, and <code>rmvn</code> or <code>rmvt</code> are called several times with the same arguments, it would make sense to create the matrix where to store the simulated random variable upfront. This can be done as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">A &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dt">nrow =</span> N, <span class="dt">ncol =</span> d)
<span class="kw">class</span>(A) &lt;-<span class="st"> "numeric"</span> <span class="co"># This is important. We need the elements of A to be of class "numeric".  </span>

<span class="kw"><a href="../reference/rmvn.html">rmvn</a></span>(N, mu, mcov, <span class="dt">A =</span> A) </code></pre></div>
<p>Notice that here <code>rmvn</code> returns <code>NULL</code>, not the simulated random vectors! These can be found in the matrix provided by the user:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">A[<span class="dv">1</span>:<span class="dv">2</span>, <span class="dv">1</span>:<span class="dv">5</span>]             </code></pre></div>
<pre><code>##           [,1]      [,2]       [,3]     [,4]      [,5]
## [1,] -1.621542 -5.518662 -0.1128524 4.182526  0.948219
## [2,]  4.010453  8.739593  3.1504857 9.331998 15.144405</code></pre>
<p>Pre-creating the matrix of random variables saves some more time:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="http://www.rdocumentation.org/packages/microbenchmark/topics/microbenchmark">microbenchmark</a></span>(<span class="kw"><a href="../reference/rmvn.html">rmvn</a></span>(N, mu, mcov, <span class="dt">ncores =</span> <span class="dv">2</span>, <span class="dt">A =</span> A),
               <span class="kw"><a href="../reference/rmvn.html">rmvn</a></span>(N, mu, mcov, <span class="dt">ncores =</span> <span class="dv">2</span>), 
               <span class="dt">times =</span> <span class="dv">200</span>)</code></pre></div>
<pre><code>## Unit: milliseconds
##                                  expr      min       lq     mean   median
##  rmvn(N, mu, mcov, ncores = 2, A = A) 2.704773 2.729230 2.803429 2.746746
##         rmvn(N, mu, mcov, ncores = 2) 2.958999 2.997206 4.114790 3.027894
##        uq       max neval cld
##  2.772958  5.444378   200  a 
##  3.290303 81.724672   200   b</code></pre>
<p>Don’t look at the median time here, the mean is much more affected by memory re-allocation.</p>
</div>
<div id="evaluating-the-multivariate-normal-and-students-t-densities" class="section level2">
<h2 class="hasAnchor">
<a href="#evaluating-the-multivariate-normal-and-students-t-densities" class="anchor"></a>Evaluating the multivariate normal and Student’s t densities</h2>
<p>Here we compare the <code>dmvn</code> function, which evaluates the multivariate normal density, with the equivalent function <code>dmvtnorm</code> (from the <code>mvtnorm</code> package). In particular we evaluate the log-density of <span class="math inline">\(10^4\)</span> twenty-dimensional random vectors:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Generating random vectors </span>
N &lt;-<span class="st"> </span><span class="dv">10000</span>
d &lt;-<span class="st"> </span><span class="dv">20</span>
mu &lt;-<span class="st"> </span><span class="dv">1</span>:d
tmp &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rnorm</span>(d^<span class="dv">2</span>), d, d)
mcov &lt;-<span class="st"> </span><span class="kw">tcrossprod</span>(tmp, tmp)
X &lt;-<span class="st"> </span><span class="kw"><a href="../reference/rmvn.html">rmvn</a></span>(N, mu, mcov)

<span class="kw"><a href="http://www.rdocumentation.org/packages/microbenchmark/topics/microbenchmark">microbenchmark</a></span>(<span class="kw"><a href="../reference/dmvn.html">dmvn</a></span>(X, mu, mcov, <span class="dt">ncores =</span> <span class="dv">2</span>, <span class="dt">log =</span> T),
               <span class="kw"><a href="../reference/dmvn.html">dmvn</a></span>(X, mu, mcov, <span class="dt">log =</span> T),
               <span class="kw"><a href="http://www.rdocumentation.org/packages/mvtnorm/topics/Mvnorm">dmvnorm</a></span>(X, mu, mcov, <span class="dt">log =</span> T), <span class="dt">times =</span> <span class="dv">500</span>)</code></pre></div>
<pre><code>## Unit: milliseconds
##                                    expr      min       lq     mean
##  dmvn(X, mu, mcov, ncores = 2, log = T) 1.522084 1.600788 1.874700
##              dmvn(X, mu, mcov, log = T) 2.634351 2.800842 3.087542
##           dmvnorm(X, mu, mcov, log = T) 2.423877 2.604765 6.031730
##    median       uq        max neval cld
##  1.748447 1.951963   4.501361   500  a 
##  2.943484 3.220942   6.823783   500  a 
##  3.695714 4.059366 110.128206   500   b</code></pre>
<p>Again, we get some speed-up using C++ code and some more from the parallelization. We get similar results if we use a multivariate Student’s t density:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># We have a namespace conflict</span>
<span class="kw"><a href="http://www.rdocumentation.org/packages/microbenchmark/topics/microbenchmark">microbenchmark</a></span>(mvnfast::<span class="kw"><a href="../reference/dmvt.html">dmvt</a></span>(X, mu, mcov, <span class="dt">df =</span> <span class="dv">4</span>, <span class="dt">ncores =</span> <span class="dv">2</span>, <span class="dt">log =</span> T),
               mvnfast::<span class="kw"><a href="../reference/dmvt.html">dmvt</a></span>(X, mu, mcov, <span class="dt">df =</span> <span class="dv">4</span>, <span class="dt">log =</span> T),
               mvtnorm::<span class="kw"><a href="../reference/dmvt.html">dmvt</a></span>(X, <span class="dt">delta =</span> mu, <span class="dt">sigma =</span> mcov, <span class="dt">df =</span> <span class="dv">4</span>, <span class="dt">log =</span> T), <span class="dt">times =</span> <span class="dv">500</span>)</code></pre></div>
<pre><code>## Unit: milliseconds
##                                                         expr      min
##      mvnfast::dmvt(X, mu, mcov, df = 4, ncores = 2, log = T) 1.698740
##                  mvnfast::dmvt(X, mu, mcov, df = 4, log = T) 2.844156
##  mvtnorm::dmvt(X, delta = mu, sigma = mcov, df = 4, log = T) 2.661140
##        lq     mean   median       uq        max neval cld
##  1.799308 2.050630 1.949040 2.047723   5.137722   500 a  
##  2.986750 3.270440 3.105357 3.326990   7.935978   500  b 
##  2.791660 5.993199 3.985475 4.141521 113.075709   500   c</code></pre>
</div>
<div id="evaluating-the-mahalanobis-distance" class="section level2">
<h2 class="hasAnchor">
<a href="#evaluating-the-mahalanobis-distance" class="anchor"></a>Evaluating the Mahalanobis distance</h2>
<p>Finally, we compare the <code>maha</code> function, which evaluates the square <a href="http://en.wikipedia.org/wiki/Mahalanobis_distance">mahalanobis distance</a> with the equivalent function <code>mahalanobis</code> (from the <code>stats</code> package). Also in the case we use <span class="math inline">\(10^4\)</span> twenty-dimensional random vectors:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Generating random vectors </span>
N &lt;-<span class="st"> </span><span class="dv">10000</span>
d &lt;-<span class="st"> </span><span class="dv">20</span>
mu &lt;-<span class="st"> </span><span class="dv">1</span>:d
tmp &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rnorm</span>(d^<span class="dv">2</span>), d, d)
mcov &lt;-<span class="st"> </span><span class="kw">tcrossprod</span>(tmp, tmp)
X &lt;-<span class="st"> </span><span class="kw"><a href="../reference/rmvn.html">rmvn</a></span>(N, mu, mcov)

<span class="kw"><a href="http://www.rdocumentation.org/packages/microbenchmark/topics/microbenchmark">microbenchmark</a></span>(<span class="kw"><a href="../reference/maha.html">maha</a></span>(X, mu, mcov, <span class="dt">ncores =</span> <span class="dv">2</span>),
               <span class="kw"><a href="../reference/maha.html">maha</a></span>(X, mu, mcov),
               <span class="kw">mahalanobis</span>(X, mu, mcov))</code></pre></div>
<pre><code>## Unit: milliseconds
##                           expr      min       lq     mean   median
##  maha(X, mu, mcov, ncores = 2) 1.408665 1.449419 1.842679 1.620487
##              maha(X, mu, mcov) 2.544158 2.617089 3.013666 2.783559
##       mahalanobis(X, mu, mcov) 2.755934 2.967716 6.446385 4.043329
##        uq       max neval cld
##  1.901139  4.400092   100  a 
##  3.032883  6.304947   100  a 
##  4.445223 89.156060   100   b</code></pre>
<p>The acceleration is similar to that obtained in the previous sections.</p>
</div>
<div id="example-mean-shift-mode-seeking-algorithm" class="section level2">
<h2 class="hasAnchor">
<a href="#example-mean-shift-mode-seeking-algorithm" class="anchor"></a>Example: mean-shift mode seeking algorithm</h2>
<p>As an example application of the <code>dmvn</code> function, we implemented the <a href="http://en.wikipedia.org/wiki/Mean-shift">mean-shift mode seeking</a> algorithm. This procedure can be used to find the mode or maxima of a kernel density function, and it can be used to set up clustering algorithms. Here we simulate <span class="math inline">\(10^4\)</span> d-dimensional random vectors from mixture of normal distributions:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">5135</span>)
N &lt;-<span class="st"> </span><span class="dv">10000</span>
d &lt;-<span class="st"> </span><span class="dv">2</span>
mu1 &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>); mu2 &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">3</span>)
Cov1 &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">2</span>), <span class="dv">2</span>, <span class="dv">2</span>)
Cov2 &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>, -<span class="fl">0.9</span>, -<span class="fl">0.9</span>, <span class="dv">1</span>), <span class="dv">2</span>, <span class="dv">2</span>)

bin &lt;-<span class="st"> </span><span class="kw">rbinom</span>(N, <span class="dv">1</span>, <span class="fl">0.5</span>)

X &lt;-<span class="st"> </span>bin *<span class="st"> </span><span class="kw"><a href="../reference/rmvn.html">rmvn</a></span>(N, mu1, Cov1) +<span class="st"> </span>(!bin) *<span class="st"> </span><span class="kw"><a href="../reference/rmvn.html">rmvn</a></span>(N, mu2, Cov2)</code></pre></div>
<p>Finally, we plot the resulting probability density and, starting from 10 initial points, we use mean-shift to converge to the nearest mode:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Plotting</span>
np &lt;-<span class="st"> </span><span class="dv">100</span>
xvals &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="kw">min</span>(X[ , <span class="dv">1</span>]), <span class="kw">max</span>(X[ , <span class="dv">1</span>]), <span class="dt">length.out =</span> np)
yvals &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="kw">min</span>(X[ , <span class="dv">2</span>]), <span class="kw">max</span>(X[ , <span class="dv">2</span>]), <span class="dt">length.out =</span> np)
theGrid &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(xvals, yvals) 
theGrid &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(theGrid)
dens &lt;-<span class="st"> </span><span class="kw"><a href="../reference/dmixn.html">dmixn</a></span>(theGrid, 
              <span class="dt">mu =</span> <span class="kw">rbind</span>(mu1, mu2), 
              <span class="dt">sigma =</span> <span class="kw">list</span>(Cov1, Cov2), 
              <span class="dt">w =</span> <span class="kw">rep</span>(<span class="dv">1</span>, <span class="dv">2</span>)/<span class="dv">2</span>)
<span class="kw">plot</span>(X[ , <span class="dv">1</span>], X[ , <span class="dv">2</span>], <span class="dt">pch =</span> <span class="st">'.'</span>, <span class="dt">lwd =</span> <span class="fl">0.01</span>, <span class="dt">col =</span> <span class="dv">3</span>)
<span class="kw">contour</span>(<span class="dt">x =</span> xvals, <span class="dt">y =</span> yvals, <span class="dt">z =</span> <span class="kw">matrix</span>(dens, np, np),
        <span class="dt">levels =</span> <span class="kw">c</span>(<span class="fl">0.002</span>, <span class="fl">0.01</span>, <span class="fl">0.02</span>, <span class="fl">0.04</span>, <span class="fl">0.08</span>, <span class="fl">0.15</span> ), <span class="dt">add =</span> <span class="ot">TRUE</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)

<span class="co"># Mean-shift</span>
<span class="kw">library</span>(plyr)
inits &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(-<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">2</span>, -<span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">0</span>, <span class="dv">0</span>, -<span class="dv">4</span>, -<span class="dv">2</span>, <span class="dv">6</span>), 
                <span class="dv">10</span>, <span class="dv">2</span>, <span class="dt">byrow =</span> <span class="ot">TRUE</span>)
traj &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/plyr/topics/alply">alply</a></span>(inits,
              <span class="dv">1</span>,
              function(input)
                  <span class="kw"><a href="../reference/ms.html">ms</a></span>(<span class="dt">X =</span> X, 
                     <span class="dt">init =</span> input, 
                     <span class="dt">H =</span> <span class="fl">0.05</span> *<span class="st"> </span><span class="kw">cov</span>(X), 
                     <span class="dt">ncores =</span> <span class="dv">2</span>, 
                     <span class="dt">store =</span> <span class="ot">TRUE</span>)$traj
              )

<span class="kw">invisible</span>( <span class="kw">lapply</span>(traj, 
                  function(input){ 
                    <span class="kw">lines</span>(input[ , <span class="dv">1</span>], input[ , <span class="dv">2</span>], <span class="dt">col =</span> <span class="dv">2</span>, <span class="dt">lwd =</span> <span class="fl">1.5</span>)
                    <span class="kw">points</span>(<span class="kw">tail</span>(input[ , <span class="dv">1</span>]), <span class="kw">tail</span>(input[ , <span class="dv">2</span>]))
           }))</code></pre></div>
<p><img src="mvnfast_files/figure-html/mixPlot-1.png" width="672" style="display:block; margin: auto"> As we can see from the plot, each initial point leads one of two points that are very close to the true mode. Notice that the bandwidth for the kernel density estimator was chosen by trial-and-error, and less arbitrary choices are certainly possible in real applications.</p>
</div>
<div id="references" class="section level2">
<h2 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h2>
<ul>
<li><p>Dirk Eddelbuettel and Romain Francois (2011). Rcpp: Seamless R and C++ Integration. Journal of Statistical Software, 40(8), 1-18. URL <a href="http://www.jstatsoft.org/v40/i08/" class="uri">http://www.jstatsoft.org/v40/i08/</a>.</p></li>
<li><p>Eddelbuettel, Dirk (2013) Seamless R and C++ Integration with Rcpp. Springer, New York. ISBN 978-1-4614-6867-7.</p></li>
<li><p>Dirk Eddelbuettel, Conrad Sanderson (2014). RcppArmadillo: Accelerating R with high-performance C++ linear algebra. Computational Statistics and Data Analysis, Volume 71, March 2014, pages 1054-1063. URL <a href="http://dx.doi.org/10.1016/j.csda.2013.02.005" class="uri">http://dx.doi.org/10.1016/j.csda.2013.02.005</a></p></li>
<li><p><a href="http://openmp.org/" class="uri">http://openmp.org/</a></p></li>
<li><p>John K. Salmon, Mark A. Moraes, Ron O. Dror, and David E. Shaw (2011). Parallel Random Numbers: As Easy as 1, 2, 3. D. E. Shaw Research, New York, NY 10036, USA.</p></li>
</ul>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#introduction">Introduction</a></li>
      <li><a href="#simulating-multivariate-normal-or-students-t-random-vectors">Simulating multivariate normal or Student’s t random vectors</a></li>
      <li><a href="#evaluating-the-multivariate-normal-and-students-t-densities">Evaluating the multivariate normal and Student’s t densities</a></li>
      <li><a href="#evaluating-the-mahalanobis-distance">Evaluating the Mahalanobis distance</a></li>
      <li><a href="#example-mean-shift-mode-seeking-algorithm">Example: mean-shift mode seeking algorithm</a></li>
      <li><a href="#references">References</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Matteo Fasiolo.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
